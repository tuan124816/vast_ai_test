{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJnwpdtXTuF7"
      },
      "source": [
        "# Training Decision Transformers with ðŸ¤— transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETOK72rJsXuw",
        "outputId": "33abf818-7d77-4a72-bdb7-feeabe197686"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmRpOylHmoSo"
      },
      "source": [
        "In this tutorial, **youâ€™ll learn to train your first Offline Decision Transformer model from scratch to make a half-cheetah run.** ðŸƒ\n",
        "\n",
        "â“ If you have questions, please post them on #study-group discord channel ðŸ‘‰ https://discord.gg/aYka4Yhff9\n",
        "\n",
        "ðŸŽ® Environments:\n",
        "- [Half Cheetah](https://www.gymlibrary.dev/environments/mujoco/half_cheetah/)\n",
        "\n",
        "â¬‡ï¸ Here's what you'll achieve at the end of this tutorial. â¬‡ï¸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h78SBsjCviBm"
      },
      "source": [
        "### Prerequisites ðŸ—ï¸\n",
        "Before diving into the notebook, you need to:\n",
        "\n",
        "ðŸ”² ðŸ“š [Read the tutorial](https://huggingface.co/blog/train-decision-transformers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCsT6KVxwARY"
      },
      "source": [
        "### Step 1: Install dependencies for model evaluation ðŸ”½"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4qntpWiEWX89",
        "outputId": "daaf53dc-f6df-4a38-a394-76049c02c263"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install -y \\\n",
        "    libgl1-mesa-dev \\\n",
        "    libgl1-mesa-glx \\\n",
        "    libglew-dev \\\n",
        "    libosmesa6-dev \\\n",
        "    software-properties-common \\\n",
        "    patchelf \\\n",
        "    xvfb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr-1h83zVsMK"
      },
      "source": [
        "### Step 2: Install and import the packages ðŸ“¦\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RuXIPJUWVrhq",
        "outputId": "0ccdc188-e769-4bbc-f210-03e4b87a59b3"
      },
      "outputs": [],
      "source": [
        "!pip install gym==0.21.0\n",
        "!pip install free-mujoco-py\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install imageio-ffmpeg\n",
        "\n",
        "!pip install colabgymrender==1.0.2\n",
        "!pip install xvfbwrapper\n",
        "!pip install imageio==2.4.1\n",
        "!pip install imageio-ffmpeg\n",
        "!pip install huggingface_hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DktITQNXTopc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tuan/Desktop/FPT/doan/doan/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "import copy\n",
        "import h5py\n",
        "from datasets import Dataset, Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from datasets import load_dataset, concatenate_datasets, load_from_disk\n",
        "import datasets\n",
        "from transformers import DecisionTransformerConfig, DecisionTransformerModel, Trainer, TrainingArguments\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1Ugq2POUmRA"
      },
      "source": [
        "### Step 3: Loading the dataset from the ðŸ¤— Hub and instantiating the model\n",
        "\n",
        "We host a number of Offline RL Datasets on the hub. Today we will be training with the halfcheetah â€œexpertâ€ dataset, hosted here on hub.\n",
        "\n",
        "First we need to import the load_dataset function from the ðŸ¤— datasets package and download the dataset to our machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "s3bLeIHqUwq7"
      },
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_DISABLED\"] = \"true\" # we diable weights and biases logging for this tutorial\n",
        "# dataset = load_from_disk(f\"/content/drive/MyDrive/hdf5_dm_test_auto_1022.hf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yEq9pLbnsutu"
      },
      "outputs": [],
      "source": [
        "# a = dataset['train'].to_pandas()\n",
        "# len(a['observations'])\n",
        "# print(len(a))\n",
        "# print(type(a))\n",
        "#in example, ['train'] is train;\n",
        "#[0] is one sample, not one time frame; means one trajectory\n",
        "#['observations'] is observation in multiple timeframe, typically a trajectory\n",
        "#[3]a timeframe in one trajectory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "56835655eddf40a1ab5388ee38147c9f",
            "8860038891054cffa38652154ba8d856",
            "0c909ce3f6754c39b2add96ae96a13e1",
            "988ef73b582b446c88b6e617f3f3b4cf",
            "9f9a04e8b76040fcb4dd077b91d0b178",
            "2a27b31cc5a7434ea72664cb27cc2d38",
            "b09f2d00fef64fa192c3b9cff67f6d15",
            "170986fda1f844df8e92231240409065",
            "6d6d9e83033a458d87acb109adf9dd88",
            "82d4764120c84a3f8d4e922bee341d26",
            "742a243e329a4bf298f16cffa75c45cd"
          ]
        },
        "id": "IxFk5n2wgkI4",
        "outputId": "4c684430-6084-4000-d72a-34a5f68a299b"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/home/tuan/Desktop/FPT/doan/cs2_data/hdf5_dm_test_auto_1.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 130\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# one_time_only = True\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# dataset = None  # Initialize dataset variable to store the concatenated datasets\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m#     '/home/tuan/Desktop/FPT/doan/cs2_data/hdf5_dm_test_auto_3.hdf5'\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# ]\u001b[39;00m\n\u001b[1;32m    126\u001b[0m hdf5_files \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/tuan/Desktop/FPT/doan/cs2_data/hdf5_dm_test_auto_1.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    128\u001b[0m \n\u001b[1;32m    129\u001b[0m ]\n\u001b[0;32m--> 130\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mhdf5_to_arrow_multiple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhdf5_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m dataset\u001b[38;5;241m.\u001b[39msave_to_disk(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/tuan/Desktop/FPT/doan/hdf5_dm_test_auto_combined.hf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[3], line 15\u001b[0m, in \u001b[0;36mhdf5_to_arrow_multiple\u001b[0;34m(hdf5_files)\u001b[0m\n\u001b[1;32m     13\u001b[0m col_action \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m col_reward \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhdf5_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# d = {}\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# dataset = Dataset.from_dict(d)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     state \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     19\u001b[0m     action \u001b[38;5;241m=\u001b[39m []\n",
            "File \u001b[0;32m~/Desktop/FPT/doan/doan/lib/python3.10/site-packages/h5py/_hl/files.py:561\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    552\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    553\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    554\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    555\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    556\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    557\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    558\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    559\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    560\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 561\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
            "File \u001b[0;32m~/Desktop/FPT/doan/doan/lib/python3.10/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
            "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/home/tuan/Desktop/FPT/doan/cs2_data/hdf5_dm_test_auto_1.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "from datasets import Dataset, concatenate_datasets\n",
        "import copy\n",
        "\n",
        "def hdf5_to_arrow_multiple(hdf5_files):\n",
        "    d = {}\n",
        "    dataset = Dataset.from_dict(d)\n",
        "    for hdf5_file in hdf5_files:\n",
        "        #1000 is the length of data\n",
        "        one_time_only = True\n",
        "        col_state = []\n",
        "        col_action = []\n",
        "        col_reward = []\n",
        "        with h5py.File(hdf5_file, 'r') as f:\n",
        "            # d = {}\n",
        "            # dataset = Dataset.from_dict(d)\n",
        "            state = []\n",
        "            action = []\n",
        "            reward = []\n",
        "            for frame_idx in range(1000):\n",
        "                helperarr = f[f'frame_{frame_idx}_helperarr'][:].tolist()\n",
        "                if helperarr  == [0,1]:\n",
        "                    helperarr = -1\n",
        "                elif helperarr  == [1,0]:\n",
        "                    helperarr = 1\n",
        "                else:\n",
        "                    helperarr = 0\n",
        "                x = f[f'frame_{frame_idx}_x'][:]\n",
        "                xaux = f[f'frame_{frame_idx}_xaux'][:]\n",
        "                y = f[f'frame_{frame_idx}_y'][:]\n",
        "                # if in testing, gun fire is semi, try this\n",
        "                # if frame_idx != 0 and frame_idx != 1000 and f[f'frame_{frame_idx-1}_y'][11] == 1 and f[f'frame_{frame_idx+1}_y'][11] == 1:\n",
        "                #    f[f'frame_{frame_idx}_y'][11] == 1\n",
        "                # if frame_idx != 0 and frame_idx != 999 and frame_idx != 1000 and f[f'frame_{frame_idx-1}_y'][11] == 1 and f[f'frame_{frame_idx+2}_y'][11] == 1: # if in testing, gun fire is semi, try this\n",
        "                #    f[f'frame_{frame_idx}_y'][11] == 1\n",
        "                #    f[f'frame_{frame_idx+1}_y'][11] == 1\n",
        "\n",
        "                state.append(np.concatenate((f[f'frame_{frame_idx}_xaux'][15:18],np.mean(x,-1).flatten()))) # change color to grey and chang it to one dimension then add health, armor, ammo to the state\n",
        "                action.append(y)\n",
        "                reward.append(helperarr)\n",
        "                # Extract trajectories and calculate rewards\n",
        "                # if helperarr  == -1 or frame_idx == 999:\n",
        "                if (1 + frame_idx) % 50 == 0:\n",
        "                    print('end trajectory')\n",
        "                    # trajectory = {\n",
        "                    #     'observations': state,\n",
        "                    #     'actions':action,\n",
        "                    #     'reward': reward}\n",
        "                    col_state.append(state)\n",
        "                    col_action.append(action)\n",
        "                    col_reward.append(reward)\n",
        "                    #creat dataset in here to reduce ram usage in return of longer runtime\n",
        "                    datatemp = Dataset.from_dict({\"observations\": [state], \"actions\": [action], 'rewards': [reward]})\n",
        "                    if one_time_only:\n",
        "                        dataset = copy.deepcopy(datatemp)\n",
        "                        one_time_only = False\n",
        "                    else:\n",
        "                        dataset = concatenate_datasets([dataset, datatemp])\n",
        "                    state = []\n",
        "                    action = []\n",
        "                    reward = []\n",
        "\n",
        "    # dataset = Dataset.from_dict({\"observations\": col_state, \"actions\": col_action, 'rewards': col_reward})\n",
        "    return dataset\n",
        "\n",
        "\n",
        "    # one_time_only = True\n",
        "    # dataset = None  # Initialize dataset variable to store the concatenated datasets\n",
        "\n",
        "    # for hdf5_file in hdf5_files:\n",
        "    #     with h5py.File(hdf5_file, 'r') as f:\n",
        "    #         state = []\n",
        "    #         action = []\n",
        "    #         reward = []\n",
        "    #         d = {}\n",
        "    #         dataset = Dataset.from_dict(d)\n",
        "\n",
        "    #         for frame_idx in range(1000):\n",
        "    #             helperarr = f[f'frame_{frame_idx}_helperarr'][:].tolist()\n",
        "    #             if helperarr  == [0,1]:\n",
        "    #                 helperarr = -1\n",
        "    #             elif helperarr  == [1,0]:\n",
        "    #                 helperarr = 1\n",
        "    #             else:\n",
        "    #                 helperarr = 0\n",
        "\n",
        "    #             x = f[f'frame_{frame_idx}_x'][:]\n",
        "    #             y = f[f'frame_{frame_idx}_y'][:]\n",
        "    #             # if in testing, gun fire is semi, try this\n",
        "    #             # if frame_idx != 0 and frame_idx != 1000 and f[f'frame_{frame_idx-1}_y'][11] == 1 and f[f'frame_{frame_idx+1}_y'][11] == 1:\n",
        "    #             #    f[f'frame_{frame_idx}_y'][11] == 1\n",
        "    #             # if frame_idx != 0 and frame_idx != 999 and frame_idx != 1000 and f[f'frame_{frame_idx-1}_y'][11] == 1 and f[f'frame_{frame_idx+2}_y'][11] == 1: # if in testing, gun fire is semi, try this\n",
        "    #             #    f[f'frame_{frame_idx}_y'][11] == 1\n",
        "    #             #    f[f'frame_{frame_idx+1}_y'][11] == 1\n",
        "    #             state.append(np.concatenate((f[f'frame_{frame_idx}_xaux'][15:18], np.mean(x, -1).flatten())))\n",
        "    #             action.append(y)\n",
        "    #             reward.append(helperarr)\n",
        "    #             # Extract trajectories and calculate rewards\n",
        "    #             # if helperarr  == -1 or frame_idx == 999:\n",
        "    #             if (frame_idx + 1) % 50 == 0:\n",
        "    #                 print('end trajectory')\n",
        "    #                 #creat dataset in here to reduce ram usage in return of longer runtime\n",
        "    #                 datatemp = Dataset.from_dict({\"observations\": [state], \"actions\": [action], 'rewards': [reward]})\n",
        "\n",
        "    #                 # Concatenate data from each file\n",
        "    #                 if one_time_only:\n",
        "    #                     dataset = copy.deepcopy(datatemp)\n",
        "    #                     one_time_only = False\n",
        "    #                 else:\n",
        "    #                     dataset = concatenate_datasets([dataset, datatemp])\n",
        "\n",
        "    #                 # Reset temporary lists\n",
        "    #                 state = []\n",
        "    #                 action = []\n",
        "    #                 reward = []\n",
        "    # # dataset = Dataset.from_dict({\"observations\": col_state, \"actions\": col_action, 'rewards': col_reward})\n",
        "    # return dataset\n",
        "\n",
        "# Example usage with multiple files\n",
        "# hdf5_files = [\n",
        "#     '/home/tuan/Desktop/FPT/doan/cs2_data/hdf5_dm_test_auto_1.hdf5',\n",
        "#     '/home/tuan/Desktop/FPT/doan/cs2_data/hdf5_dm_test_auto_2.hdf5',\n",
        "#     '/home/tuan/Desktop/FPT/doan/cs2_data/hdf5_dm_test_auto_3.hdf5'\n",
        "# ]\n",
        "hdf5_files = [\n",
        "    '/home/tuan/Desktop/FPT/doan/cs2_data/hdf5_dm_test_auto_1.hdf5',\n",
        "\n",
        "]\n",
        "dataset = hdf5_to_arrow_multiple(hdf5_files)\n",
        "dataset.save_to_disk(\"/home/tuan/Desktop/FPT/doan/hdf5_dm_test_auto_combined.hf\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396,
          "referenced_widgets": [
            "a8a8acb31c1743d1b09233d06f5329e6",
            "9cb62e32616c4217bff31960b48aac7a",
            "fa7c562dd6ac489285bfcb53a738e216",
            "6126b69f6487464b88f14fef402d7205",
            "52f428497cab4f1788280acde19decf8",
            "f66b5dc66bec473c9687959a86dede69",
            "33956b8453ce414a98fe2d9e8c9c62ed",
            "39dc519caba34bbdb40cce231326d52e",
            "cf578bd1a7cc4f0a94564a2a564ba991",
            "3f6b8104267844168a3d1db57e9ff1cc",
            "3f75f9ba8a76494191c15650dfe6795b"
          ]
        },
        "collapsed": true,
        "id": "RMdG_xRMrqEY",
        "outputId": "3e22d623-1428-4d4c-a986-944ac78d1e1c"
      },
      "outputs": [],
      "source": [
        "def hdf5_to_arrow(hdf5_file):\n",
        "    #1000 is the length of data\n",
        "    one_time_only = True\n",
        "    col_state = []\n",
        "    col_action = []\n",
        "    col_reward = []\n",
        "    with h5py.File(hdf5_file, 'r') as f:\n",
        "        d = {}\n",
        "        dataset = Dataset.from_dict(d)\n",
        "        state = []\n",
        "        action = []\n",
        "        reward = []\n",
        "        for frame_idx in range(1000):\n",
        "            helperarr = f[f'frame_{frame_idx}_helperarr'][:].tolist()\n",
        "            if helperarr  == [0,1]:\n",
        "              helperarr = -1\n",
        "            elif helperarr  == [1,0]:\n",
        "              helperarr = 1\n",
        "            else:\n",
        "              helperarr = 0\n",
        "            x = f[f'frame_{frame_idx}_x'][:]\n",
        "            xaux = f[f'frame_{frame_idx}_xaux'][:]\n",
        "            y = f[f'frame_{frame_idx}_y'][:]\n",
        "            # if in testing, gun fire is semi, try this\n",
        "            # if frame_idx != 0 and frame_idx != 1000 and f[f'frame_{frame_idx-1}_y'][11] == 1 and f[f'frame_{frame_idx+1}_y'][11] == 1:\n",
        "            #    f[f'frame_{frame_idx}_y'][11] == 1\n",
        "            # if frame_idx != 0 and frame_idx != 999 and frame_idx != 1000 and f[f'frame_{frame_idx-1}_y'][11] == 1 and f[f'frame_{frame_idx+2}_y'][11] == 1: # if in testing, gun fire is semi, try this\n",
        "            #    f[f'frame_{frame_idx}_y'][11] == 1\n",
        "            #    f[f'frame_{frame_idx+1}_y'][11] == 1\n",
        "\n",
        "            state.append(np.concatenate((f[f'frame_{frame_idx}_xaux'][15:18],np.mean(x,-1).flatten()))) # change color to grey and chang it to one dimension then add health, armor, ammo to the state\n",
        "            action.append(y)\n",
        "            reward.append(helperarr)\n",
        "            # Extract trajectories and calculate rewards\n",
        "            # if helperarr  == -1 or frame_idx == 999:\n",
        "            if (1 + frame_idx) % 50 == 0:\n",
        "                print('end trajectory')\n",
        "                # trajectory = {\n",
        "                #     'observations': state,\n",
        "                #     'actions':action,\n",
        "                #     'reward': reward}\n",
        "                col_state.append(state)\n",
        "                col_action.append(action)\n",
        "                col_reward.append(reward)\n",
        "                #creat dataset in here to reduce ram usage in return of longer runtime\n",
        "                datatemp = Dataset.from_dict({\"observations\": [state], \"actions\": [action], 'rewards': [reward]})\n",
        "                if one_time_only:\n",
        "                  dataset = copy.deepcopy(datatemp)\n",
        "                  one_time_only = False\n",
        "                else:\n",
        "                  dataset = concatenate_datasets([dataset, datatemp])\n",
        "                state = []\n",
        "                action = []\n",
        "                reward = []\n",
        "\n",
        "    # dataset = Dataset.from_dict({\"observations\": col_state, \"actions\": col_action, 'rewards': col_reward})\n",
        "    return dataset\n",
        "\n",
        "# # Example usage\n",
        "# hdf5_file = f'/content/drive/MyDrive/cs2_data/hdf5_dm_test_auto_1.hdf5'\n",
        "# dataset = hdf5_to_arrow(hdf5_file)\n",
        "# dataset.save_to_disk(f\"/content/drive/MyDrive/cs2_data/hdf5_dm_test_auto_1.hf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "1\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "2\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "3\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "4\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n",
            "end trajectory\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 41.21 examples/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "save_dir = 'raw_data/'\n",
        "index = 0\n",
        "dataset_full = None\n",
        "for files in glob.glob(save_dir + '*'):\n",
        "    dataset = hdf5_to_arrow(files)\n",
        "    if index == 0:\n",
        "        dataset_full = copy.deepcopy(dataset)\n",
        "    else:\n",
        "        dataset_full = concatenate_datasets([dataset_full, dataset])\n",
        "        if index % 4 == 0:\n",
        "            dataset.save_to_disk(f\"hdf5_dm_test_auto_combine.hf\")\n",
        "    index += 1\n",
        "    print(index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XI0Y3panVr8h"
      },
      "outputs": [],
      "source": [
        "# plt.imshow(np.array(dataset[1]['observations'][15]), cmap=cm.gray)\n",
        "# for n in range(len(dataset)):\n",
        "#   print(len(dataset[n]['rewards']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "A5GnYozW3YqA",
        "outputId": "a26dc6d9-d17c-43bc-fcae-37b1f7947fd3"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/content/drive/MyDrive/hdf5_dm_test_auto_1022.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/content/drive/MyDrive/hdf5_dm_test_auto_1022.hdf5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#1000 frame (0-999)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Accessing the first frame's datasets\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#frame_helperarr = f['frame_0_helperarr'][:]  # Reading the helper array\u001b[39;00m\n\u001b[1;32m      5\u001b[0m frame_x \u001b[38;5;241m=\u001b[39m f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe_100_x\u001b[39m\u001b[38;5;124m'\u001b[39m][:]  \u001b[38;5;66;03m# Reading the image data AKA state\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/FPT/doan/doan/lib/python3.10/site-packages/h5py/_hl/files.py:561\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    552\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    553\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    554\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    555\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    556\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    557\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    558\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    559\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    560\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 561\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
            "File \u001b[0;32m~/Desktop/FPT/doan/doan/lib/python3.10/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
            "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/content/drive/MyDrive/hdf5_dm_test_auto_1022.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ],
      "source": [
        "f = h5py.File(f'/content/drive/MyDrive/hdf5_dm_test_auto_1022.hdf5', 'r')\n",
        "#1000 frame (0-999)\n",
        "# Accessing the first frame's datasets\n",
        "#frame_helperarr = f['frame_0_helperarr'][:]  # Reading the helper array\n",
        "frame_x = f['frame_100_x'][:]  # Reading the image data AKA state\n",
        "frame_xaux = f['frame_100_xaux'][:]  # Reading auxiliary data\n",
        "\n",
        "frame_y = f['frame_100_y'][:]  # Reading the y data AKA action\n",
        "frame_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0End7tuIdA4",
        "outputId": "36076d60-089d-43af-de05-540ea1408bcf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [1.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [1.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [1.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [1.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " [1.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0]]"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "states = []\n",
        "states.extend(dataset['actions'][4])\n",
        "states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "qQ6Kd-nClnZp"
      },
      "outputs": [],
      "source": [
        "def dim(a):\n",
        "    if not type(a) == list:\n",
        "        return []\n",
        "    return [len(a)] + dim(a[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RGwzmpCJfsx",
        "outputId": "b851b7b4-1168-4cac-e2fb-5c5769896973"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[51]"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dim(dataset[0][\"actions\"][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFmTdHoHUD13"
      },
      "source": [
        "### Step 4: Defining a custom DataCollator for the transformers Trainer class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "l1QzZHmPUM4p"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class DecisionTransformerGymDataCollator:\n",
        "    return_tensors: str = \"pt\"\n",
        "    max_len: int = 20 #subsets of the episode we use for training\n",
        "    state_dim: int = 61803  # size of state space\n",
        "    act_dim: int = 51  # size of action space\n",
        "    max_ep_len: int = 1000 # max episode length in the dataset\n",
        "    scale: float = 1000.0  # normalization of rewards/returns\n",
        "    state_mean: np.array = None  # to store state means\n",
        "    state_std: np.array = None  # to store state stds\n",
        "    p_sample: np.array = None  # a distribution to take account trajectory lengths\n",
        "    n_traj: int = 0 # to store the number of trajectories in the dataset\n",
        "\n",
        "    def __init__(self, dataset) -> None:        \n",
        "        self.act_dim = len(dataset[0][\"actions\"][0])\n",
        "        self.state_dim = len(dataset[0][\"observations\"][0])\n",
        "        self.dataset = dataset\n",
        "        # calculate dataset stats for normalization of states\n",
        "        states = []\n",
        "        traj_lens = []\n",
        "        for obs in dataset[\"observations\"]:\n",
        "            states.extend(obs)\n",
        "            traj_lens.append(len(obs))\n",
        "        self.n_traj = len(traj_lens)\n",
        "        states = np.vstack(states)\n",
        "        self.state_mean, self.state_std = np.mean(states, axis=0), np.std(states, axis=0) + 1e-6\n",
        "\n",
        "        traj_lens = np.array(traj_lens)\n",
        "        self.p_sample = traj_lens / sum(traj_lens)\n",
        "\n",
        "    def _discount_cumsum(self, x, gamma):\n",
        "        discount_cumsum = np.zeros_like(x)\n",
        "        discount_cumsum[-1] = x[-1]\n",
        "        for t in reversed(range(x.shape[0] - 1)):\n",
        "            discount_cumsum[t] = x[t] + gamma * discount_cumsum[t + 1]\n",
        "        return discount_cumsum\n",
        "\n",
        "    def __call__(self, features):\n",
        "        batch_size = len(features)\n",
        "        # this is a bit of a hack to be able to sample of a non-uniform distribution\n",
        "        batch_inds = np.random.choice(\n",
        "            np.arange(self.n_traj),\n",
        "            size=batch_size,\n",
        "            replace=True,\n",
        "            p=self.p_sample,  # reweights so we sample according to timesteps\n",
        "        )\n",
        "        # a batch of dataset features\n",
        "        s, a, r, rtg, timesteps, mask = [], [], [], [], [], []\n",
        "\n",
        "        for ind in batch_inds:\n",
        "            # for feature in features:\n",
        "            feature = self.dataset[int(ind)]\n",
        "            si = random.randint(0, len(feature[\"rewards\"]) - 1) #random starting index for each selected trajectory.\n",
        "\n",
        "            # get sequences from dataset\n",
        "            s.append(np.array(feature[\"observations\"][si : si + self.max_len]).reshape(1, -1, self.state_dim)) # take max_len time frames from starting index(si)\n",
        "            a.append(np.array(feature[\"actions\"][si : si + self.max_len]).reshape(1, -1, self.act_dim))\n",
        "            r.append(np.array(feature[\"rewards\"][si : si + self.max_len]).reshape(1, -1, 1))\n",
        "\n",
        "            # d.append(np.array(feature[\"dones\"][si : si + self.max_len]).reshape(1, -1))\n",
        "            timesteps.append(np.arange(si, si + s[-1].shape[1]).reshape(1, -1))\n",
        "            timesteps[-1][timesteps[-1] >= self.max_ep_len] = self.max_ep_len - 1  # padding cutoff\n",
        "            rtg.append(\n",
        "                self._discount_cumsum(np.array(feature[\"rewards\"][si:]), gamma=1.0)[\n",
        "                    : s[-1].shape[1]   # TODO check the +1 removed here\n",
        "                ].reshape(1, -1, 1)\n",
        "            )\n",
        "            # print(rtg[-1].shape[1])\n",
        "            if rtg[-1].shape[1] < s[-1].shape[1]:\n",
        "                print(\"if true\")\n",
        "                rtg[-1] = np.concatenate([rtg[-1], np.zeros((1, 1, 1))], axis=1)\n",
        "\n",
        "            # padding and state + reward normalization\n",
        "            tlen = s[-1].shape[1]\n",
        "            # print(s[-1].shape)\n",
        "            # print(tlen)\n",
        "            s[-1] = np.concatenate([np.zeros((1, self.max_len - tlen, self.state_dim)), s[-1]], axis=1)\n",
        "            s[-1] = (s[-1] - self.state_mean) / self.state_std\n",
        "            a[-1] = np.concatenate(\n",
        "                [np.ones((1, self.max_len - tlen, self.act_dim)) * -10.0, a[-1]],\n",
        "                axis=1,\n",
        "            )\n",
        "            r[-1] = np.concatenate([np.zeros((1, self.max_len - tlen, 1)), r[-1]], axis=1)\n",
        "            # d[-1] = np.concatenate([np.ones((1, self.max_len - tlen)) * 2, d[-1]], axis=1)\n",
        "            rtg[-1] = np.concatenate([np.zeros((1, self.max_len - tlen, 1)), rtg[-1]], axis=1) / self.scale\n",
        "            timesteps[-1] = np.concatenate([np.zeros((1, self.max_len - tlen)), timesteps[-1]], axis=1)\n",
        "            mask.append(np.concatenate([np.zeros((1, self.max_len - tlen)), np.ones((1, tlen))], axis=1))\n",
        "\n",
        "        s = torch.from_numpy(np.concatenate(s, axis=0)).float()\n",
        "        a = torch.from_numpy(np.concatenate(a, axis=0)).float()\n",
        "        r = torch.from_numpy(np.concatenate(r, axis=0)).float()\n",
        "        # d = torch.from_numpy(np.concatenate(d, axis=0))\n",
        "        rtg = torch.from_numpy(np.concatenate(rtg, axis=0)).float()\n",
        "        timesteps = torch.from_numpy(np.concatenate(timesteps, axis=0)).long()\n",
        "        mask = torch.from_numpy(np.concatenate(mask, axis=0)).float()\n",
        "\n",
        "        return {\n",
        "            \"states\": s,\n",
        "            \"actions\": a,\n",
        "            \"rewards\": r,\n",
        "            \"returns_to_go\": rtg,\n",
        "            \"timesteps\": timesteps,\n",
        "            \"attention_mask\": mask,\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmTRGPKYUVFG"
      },
      "source": [
        "### Step 5: Extending the Decision Transformer Model to include a loss function\n",
        "\n",
        "In order to train the model with the ðŸ¤— trainer class, we first need to ensure the dictionary it returns contains a loss, in this case L-2 norm of the models action predictions and the targets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "TrPmaq4VlDHL"
      },
      "outputs": [],
      "source": [
        "def custom_loss(y_true, y_pred):\n",
        "        # y_true is shape [n_batch, n_timesteps, n_keys+n_clicks+n_mouse_x+n_mouse_y+n_reward+n_advantage]\n",
        "        # where n_reward and n_advantage must =1\n",
        "        # y_pred is shape [n_batch, n_timesteps, n_keys+n_clicks+n_mouse_x+n_mouse_y+n_val]\n",
        "        # we'll use y_true to send in reward and eventually original advantage fn (or could recompute this?)\n",
        "\n",
        "        # wasd keys\n",
        "        loss1a = losses.binary_crossentropy(y_true[:,:,0:4],\n",
        "                                            y_pred[:,:,0:4])\n",
        "        # space key\n",
        "        loss1b = losses.binary_crossentropy(y_true[:,:,4:5],\n",
        "                                            y_pred[:,:,4:5])\n",
        "        # reload key\n",
        "        loss1c = losses.binary_crossentropy(y_true[:,:,n_keys-1:n_keys],\n",
        "                                            y_pred[:,:,n_keys-1:n_keys])\n",
        "\n",
        "        # weapon switches, 1,2,3\n",
        "        loss1d = losses.binary_crossentropy(y_true[:,:,n_keys-4:n_keys-1],\n",
        "                                            y_pred[:,:,n_keys-4:n_keys-1])\n",
        "\n",
        "        # all other keys\n",
        "        # loss1d = losses.binary_crossentropy(y_true[:,:,5:n_keys-1],\n",
        "        #                                     y_pred[:,:,5:n_keys-1])\n",
        "        # left click\n",
        "        loss2a = losses.binary_crossentropy(y_true[:,:,n_keys:n_keys+1],\n",
        "                                            y_pred[:,:,n_keys:n_keys+1])\n",
        "        # right click\n",
        "        loss2b = losses.binary_crossentropy(y_true[:,:,n_keys+1:n_keys+n_clicks],\n",
        "                                            y_pred[:,:,n_keys+1:n_keys+n_clicks])\n",
        "        # mouse move x\n",
        "        loss3 = losses.categorical_crossentropy(y_true[:,:,n_keys+n_clicks:n_keys+n_clicks+n_mouse_x],\n",
        "                                                y_pred[:,:,n_keys+n_clicks:n_keys+n_clicks+n_mouse_x])\n",
        "        # mouse move y\n",
        "        loss4 = losses.categorical_crossentropy(y_true[:,:,n_keys+n_clicks+n_mouse_x:n_keys+n_clicks+n_mouse_x+n_mouse_y],\n",
        "                                                y_pred[:,:,n_keys+n_clicks+n_mouse_x:n_keys+n_clicks+n_mouse_x+n_mouse_y])\n",
        "\n",
        "        # critic loss -- measuring between consecutive time steps\n",
        "        #  = ((reward_t + gamma  v_t+1) - v_t)^2\n",
        "        # can't really decide whether to use reward_t or reward_t+1, but guess it doesn't matter too much\n",
        "        loss_crit = 10*losses.MSE(y_true[:,:-1,n_keys+n_clicks+n_mouse_x+n_mouse_y:n_keys+n_clicks+n_mouse_x+n_mouse_y+1]\n",
        "                           + GAMMA*y_pred[:,1:,n_keys+n_clicks+n_mouse_x+n_mouse_y:n_keys+n_clicks+n_mouse_x+n_mouse_y+1]\n",
        "                           ,y_pred[:,:-1,n_keys+n_clicks+n_mouse_x+n_mouse_y:n_keys+n_clicks+n_mouse_x+n_mouse_y+1])\n",
        "\n",
        "        return K.concatenate([loss1a, loss1b, loss1c, loss2a, loss3, loss4, loss_crit])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrainableDT(DecisionTransformerModel):\n",
        "    def __init__(self, config, gamma=0.99):\n",
        "        super().__init__(config)\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, **kwargs):\n",
        "        print('here0')\n",
        "        output = super().forward(**kwargs)\n",
        "        action_preds = output[1]\n",
        "        action_targets = kwargs[\"actions\"]\n",
        "        attention_mask = kwargs[\"attention_mask\"]\n",
        "\n",
        "        print(\"action_preds shape:\", action_preds.shape)\n",
        "        print(\"action_targets shape:\", action_targets.shape)\n",
        "\n",
        "\n",
        "        # Reshape for custom loss\n",
        "        n_keys = 11\n",
        "        n_clicks = 2\n",
        "        mouse_x_possibles = [-1000.0,-500.0, -300.0, -200.0, -100.0, -60.0, -30.0, -20.0, -10.0, -4.0, -2.0, -0.0, 2.0, 4.0, 10.0, 20.0, 30.0, 60.0, 100.0, 200.0, 300.0, 500.0,1000.0]\n",
        "        mouse_y_possibles = [-200.0, -100.0, -50.0, -20.0, -10.0, -4.0, -2.0, -0.0, 2.0, 4.0, 10.0, 20.0, 50.0, 100.0, 200.0]\n",
        "        n_mouse_x = len(mouse_x_possibles)\n",
        "        n_mouse_y = len(mouse_y_possibles)\n",
        "\n",
        "        action_preds = action_preds[attention_mask > 0]\n",
        "        action_targets = action_targets[attention_mask > 0]\n",
        "\n",
        "        # Loss calculations based on each category\n",
        "        loss1a = F.binary_cross_entropy(action_preds[:, :4], action_targets[:, :4])\n",
        "        loss1b = F.binary_cross_entropy(action_preds[:, 4:5], action_targets[:, 4:5])\n",
        "        loss1c = F.binary_cross_entropy(action_preds[:, n_keys-1:n_keys], action_targets[:, n_keys-1:n_keys])\n",
        "        loss1d = F.binary_cross_entropy(action_preds[:, n_keys-4:n_keys-1], action_targets[:, n_keys-4:n_keys-1])\n",
        "        loss2a = F.binary_cross_entropy(action_preds[:, n_keys:n_keys+1], action_targets[:, n_keys:n_keys+1])\n",
        "        loss2b = F.binary_cross_entropy(action_preds[:, n_keys+1:n_keys+n_clicks], action_targets[:, n_keys+1:n_keys+n_clicks])\n",
        "        print('here1')\n",
        "        loss3 = F.cross_entropy(action_preds[:, n_keys+n_clicks:n_keys+n_clicks+n_mouse_x], action_targets[:, n_keys+n_clicks:n_keys+n_clicks+n_mouse_x].argmax(dim=1))\n",
        "        loss4 = F.cross_entropy(action_preds[:, n_keys+n_clicks+n_mouse_x:n_keys+n_clicks+n_mouse_x+n_mouse_y], action_targets[:, n_keys+n_clicks+n_mouse_x:n_keys+n_clicks+n_mouse_x+n_mouse_y].argmax(dim=1))\n",
        "        print('here2')\n",
        "        # Critic loss\n",
        "        reward_t = action_targets[:, n_keys + n_clicks + n_mouse_x + n_mouse_y : n_keys + n_clicks + n_mouse_x + n_mouse_y + 1]\n",
        "        v_t = action_preds[:, n_keys + n_clicks + n_mouse_x + n_mouse_y : n_keys + n_clicks + n_mouse_x + n_mouse_y + 1]\n",
        "        v_t_next = action_preds[:, 1:, n_keys + n_clicks + n_mouse_x + n_mouse_y : n_keys + n_clicks + n_mouse_x + n_mouse_y + 1]\n",
        "\n",
        "        loss_crit = 10 * F.mse_loss(reward_t[:, :-1] + self.gamma * v_t_next, v_t[:, :-1])\n",
        "        print('here3')\n",
        "        # Total loss\n",
        "        total_loss = sum([loss1a, loss1b, loss1c, loss1d, loss2a, loss2b, loss3, loss4, loss_crit])\n",
        "\n",
        "        return {\"loss\": total_loss}\n",
        "\n",
        "    def original_forward(self, **kwargs):\n",
        "        return super().forward(**kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "action_preds shape: torch.Size([315, 51]) dtype: torch.float32\n",
        "\n",
        "action_targets shape: torch.Size([315, 51]) dtype: torch.float32\n",
        "\n",
        "action_preds sample: tensor([ 0.1753, -0.1965, -0.2445, -0.3211,  0.3310,  0.0852,  0.0756, -0.1474,\n",
        "         0.0823,  0.0814], device='cuda:0', grad_fn=<SliceBackward0>)\n",
        "         \n",
        "action_targets sample: tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bwZp7hhFUh5u"
      },
      "outputs": [],
      "source": [
        "test_value = 0\n",
        "class TrainableDT(DecisionTransformerModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "    def forward(self, **kwargs):\n",
        "        global test_value\n",
        "        test_value = kwargs\n",
        "        # print(kwargs)\n",
        "        print(type(kwargs))\n",
        "        # print(kwargs.shape)\n",
        "        output = super().forward(**kwargs)\n",
        "        # add the DT loss\n",
        "        action_preds = output[1]\n",
        "        action_targets = kwargs[\"actions\"]\n",
        "        attention_mask = kwargs[\"attention_mask\"]\n",
        "        act_dim = action_preds.shape[2]\n",
        "        action_preds = action_preds.reshape(-1, act_dim)[attention_mask.reshape(-1) > 0]\n",
        "        action_targets = action_targets.reshape(-1, act_dim)[attention_mask.reshape(-1) > 0]\n",
        "\n",
        "        # **Debugging Statements**:\n",
        "        print(\"action_preds shape:\", action_preds.shape, \"dtype:\", action_preds.dtype)\n",
        "        print(\"action_targets shape:\", action_targets.shape, \"dtype:\", action_targets.dtype)\n",
        "        print(\"action_preds sample:\", action_preds[0, :10])\n",
        "        print(\"action_targets sample:\", action_targets[0, :10])\n",
        "\n",
        "        loss = torch.mean((action_preds - action_targets) ** 2)\n",
        "\n",
        "        return {\"loss\": loss}\n",
        "\n",
        "    def original_forward(self, **kwargs):\n",
        "        return super().forward(**kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zIJCY3b3pQAh"
      },
      "outputs": [],
      "source": [
        "collator = DecisionTransformerGymDataCollator(dataset_full)\n",
        "\n",
        "config = DecisionTransformerConfig(state_dim=collator.state_dim, act_dim=collator.act_dim)\n",
        "model = TrainableDT(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TrainableDT(\n",
              "  (encoder): DecisionTransformerGPT2Model(\n",
              "    (wte): Embedding(1, 128)\n",
              "    (wpe): Embedding(1024, 128)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-2): 3 x DecisionTransformerGPT2Block(\n",
              "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): DecisionTransformerGPT2Attention(\n",
              "          (c_attn): Conv1D(nf=384, nx=128)\n",
              "          (c_proj): Conv1D(nf=128, nx=128)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): DecisionTransformerGPT2MLP(\n",
              "          (c_fc): Conv1D(nf=512, nx=128)\n",
              "          (c_proj): Conv1D(nf=128, nx=512)\n",
              "          (act): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (embed_timestep): Embedding(4096, 128)\n",
              "  (embed_return): Linear(in_features=1, out_features=128, bias=True)\n",
              "  (embed_state): Linear(in_features=61803, out_features=128, bias=True)\n",
              "  (embed_action): Linear(in_features=51, out_features=128, bias=True)\n",
              "  (embed_ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  (predict_state): Linear(in_features=128, out_features=61803, bias=True)\n",
              "  (predict_action): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=51, bias=True)\n",
              "    (1): Tanh()\n",
              "  )\n",
              "  (predict_return): Linear(in_features=128, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "RoKlHcpP5XpS"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'int' object has no attribute 'keys'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m()\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'keys'"
          ]
        }
      ],
      "source": [
        "# test_value.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAzeWL6DAPf3",
        "outputId": "5ccd82d6-6b88-46cf-9273-886ab0122b5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([20, 20, 51])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test_value[\"actions\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jppNQU4Uuus"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJJ2mr_cU4eE"
      },
      "source": [
        "### Step 6: Defining the training hyperparameters and training the model\n",
        "Here, we define the training hyperparameters and our Trainer class that we'll use to train our Decision Transformer model.\n",
        "\n",
        "This step takes about an hour, so you may leave it running. Note the authors train for at least 3 hours, so the results presented here are not as performant as the models hosted on the ðŸ¤— hub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nNzzKWuuU9I4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "  0%|          | 0/240 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "action_preds shape: torch.Size([1036, 51]) dtype: torch.float32\n",
            "action_targets shape: torch.Size([1036, 51]) dtype: torch.float32\n",
            "action_preds sample: tensor([-0.3136, -0.2832, -0.2762,  0.2300, -0.3040,  0.1782, -0.1402,  0.0728,\n",
            "         0.3049,  0.2600], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "action_targets sample: tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 0.], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/240 [02:14<8:56:59, 134.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "action_preds shape: torch.Size([561, 51]) dtype: torch.float32\n",
            "action_targets shape: torch.Size([561, 51]) dtype: torch.float32\n",
            "action_preds sample: tensor([-0.1460, -0.3046,  0.1718, -0.2603, -0.2478, -0.0522,  0.0171, -0.2396,\n",
            "         0.1339,  0.0660], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "action_targets sample: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|â–         | 3/240 [04:31<5:37:47, 85.52s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "action_preds shape: torch.Size([1031, 51]) dtype: torch.float32\n",
            "action_targets shape: torch.Size([1031, 51]) dtype: torch.float32\n",
            "action_preds sample: tensor([-0.2919,  0.1829,  0.1558, -0.2505,  0.2847, -0.2647,  0.0158, -0.2955,\n",
            "        -0.1254, -0.0491], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "action_targets sample: tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "<class 'dict'>\n",
            "action_preds shape: torch.Size([520, 51]) dtype: torch.float32\n",
            "action_targets shape: torch.Size([520, 51]) dtype: torch.float32\n",
            "action_preds sample: tensor([ 0.0376,  0.0410,  0.0044, -0.3693, -0.0781, -0.4217,  0.1920, -0.2554,\n",
            "        -0.1016, -0.5075], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "action_targets sample: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|â–         | 5/240 [06:47<4:59:28, 76.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "action_preds shape: torch.Size([1020, 51]) dtype: torch.float32\n",
            "action_targets shape: torch.Size([1020, 51]) dtype: torch.float32\n",
            "action_preds sample: tensor([ 0.0897,  0.2966, -0.2781,  0.2756, -0.3582, -0.5010, -0.1810,  0.2319,\n",
            "        -0.1146, -0.0552], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "action_targets sample: tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "<class 'dict'>\n",
            "action_preds shape: torch.Size([610, 51]) dtype: torch.float32\n",
            "action_targets shape: torch.Size([610, 51]) dtype: torch.float32\n",
            "action_preds sample: tensor([ 0.1028,  0.0126, -0.0335, -0.2816,  0.0303,  0.2255,  0.1603, -0.0582,\n",
            "        -0.3262, -0.0513], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "action_targets sample: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|â–Ž         | 7/240 [08:59<4:40:03, 72.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "action_preds shape: torch.Size([1101, 51]) dtype: torch.float32\n",
            "action_targets shape: torch.Size([1101, 51]) dtype: torch.float32\n",
            "action_preds sample: tensor([ 0.2204,  0.1718, -0.2221,  0.2577, -0.1081,  0.1107,  0.1242,  0.0143,\n",
            "        -0.1593,  0.0550], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "action_targets sample: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
            "<class 'dict'>\n",
            "action_preds shape: torch.Size([589, 51]) dtype: torch.float32\n",
            "action_targets shape: torch.Size([589, 51]) dtype: torch.float32\n",
            "action_preds sample: tensor([-0.0104, -0.0406, -0.3376, -0.1949,  0.0664, -0.1023, -0.1778, -0.2521,\n",
            "        -0.1302,  0.0712], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "action_targets sample: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 20\u001b[0m\n\u001b[1;32m      1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      2\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./trained_models/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     remove_unused_columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     max_grad_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     14\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     15\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     16\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mdataset_full,\n\u001b[1;32m     17\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mcollator,\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/FPT/doan/doan/lib/python3.10/site-packages/transformers/trainer.py:2122\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2120\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2123\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/FPT/doan/doan/lib/python3.10/site-packages/transformers/trainer.py:2426\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2424\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2425\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[0;32m-> 2426\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2427\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs \u001b[38;5;129;01min\u001b[39;00m batch_samples:\n\u001b[1;32m   2428\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[0;32m~/Desktop/FPT/doan/doan/lib/python3.10/site-packages/transformers/trainer.py:5038\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches)\u001b[0m\n\u001b[1;32m   5036\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m   5037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5038\u001b[0m         batch_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m   5039\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   5040\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/FPT/doan/doan/lib/python3.10/site-packages/accelerate/data_loader.py:550\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/FPT/doan/doan/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
            "File \u001b[0;32m~/Desktop/FPT/doan/doan/lib/python3.10/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/Desktop/FPT/doan/doan/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[7], line 52\u001b[0m, in \u001b[0;36mDecisionTransformerGymDataCollator.__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     48\u001b[0m s, a, r, rtg, timesteps, mask \u001b[38;5;241m=\u001b[39m [], [], [], [], [], []\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m batch_inds:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# for feature in features:\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m     feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mind\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m     si \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(feature[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrewards\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#random starting index for each selected trajectory.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# get sequences from dataset\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/FPT/doan/doan/lib/python3.10/site-packages/datasets/arrow_dataset.py:2762\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2760\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2761\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/FPT/doan/doan/lib/python3.10/site-packages/datasets/arrow_dataset.py:2747\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2745\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2746\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[0;32m-> 2747\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   2749\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2750\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
            "File \u001b[0;32m~/Desktop/FPT/doan/doan/lib/python3.10/site-packages/datasets/formatting/formatting.py:647\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    646\u001b[0m     pa_table_to_format \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mdrop(col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m pa_table\u001b[38;5;241m.\u001b[39mcolumn_names \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m format_columns)\n\u001b[0;32m--> 647\u001b[0m     formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table_to_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_all_columns:\n\u001b[1;32m    649\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formatted_output, MutableMapping):\n",
            "File \u001b[0;32m~/Desktop/FPT/doan/doan/lib/python3.10/site-packages/datasets/formatting/formatting.py:403\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
            "File \u001b[0;32m~/Desktop/FPT/doan/doan/lib/python3.10/site-packages/datasets/formatting/formatting.py:443\u001b[0m, in \u001b[0;36mPythonFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyRow(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 443\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_arrow_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_row(row)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
            "File \u001b[0;32m~/Desktop/FPT/doan/doan/lib/python3.10/site-packages/datasets/formatting/formatting.py:145\u001b[0m, in \u001b[0;36mPythonArrowExtractor.extract_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unnest(\u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pydict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./trained_models/\",\n",
        "    remove_unused_columns=False,\n",
        "    num_train_epochs=120,\n",
        "    per_device_train_batch_size=64,\n",
        "    learning_rate=1e-4,\n",
        "    weight_decay=1e-4,\n",
        "    warmup_ratio=0.1,\n",
        "    optim=\"adamw_torch\",\n",
        "    max_grad_norm=0.25,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset_full,\n",
        "    data_collator=collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGllLteiTIe5"
      },
      "outputs": [],
      "source": [
        "    state_preds, action_preds, return_preds = model.original_forward(\n",
        "        states=states,\n",
        "        actions=actions,\n",
        "        rewards=rewards,\n",
        "        returns_to_go=returns_to_go,\n",
        "        timesteps=timesteps,\n",
        "        attention_mask=attention_mask,\n",
        "        return_dict=False,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNaj6bOkp3bt"
      },
      "source": [
        "### Step 7: Visualize the performance of the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0NhIn4up26c"
      },
      "outputs": [],
      "source": [
        "import mujoco_py\n",
        "import gym\n",
        "\n",
        "from colabgymrender.recorder import Recorder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-izl68BqUG5"
      },
      "outputs": [],
      "source": [
        "# Function that gets an action from the model using autoregressive prediction with a window of the previous 20 timesteps.\n",
        "def get_action(model, states, actions, rewards, returns_to_go, timesteps):\n",
        "    # This implementation does not condition on past rewards\n",
        "\n",
        "    states = states.reshape(1, -1, model.config.state_dim)\n",
        "    actions = actions.reshape(1, -1, model.config.act_dim)\n",
        "    returns_to_go = returns_to_go.reshape(1, -1, 1)\n",
        "    timesteps = timesteps.reshape(1, -1)\n",
        "\n",
        "    states = states[:, -model.config.max_length :]\n",
        "    actions = actions[:, -model.config.max_length :]\n",
        "    returns_to_go = returns_to_go[:, -model.config.max_length :]\n",
        "    timesteps = timesteps[:, -model.config.max_length :]\n",
        "    padding = model.config.max_length - states.shape[1]\n",
        "    # pad all tokens to sequence length\n",
        "    attention_mask = torch.cat([torch.zeros(padding), torch.ones(states.shape[1])])\n",
        "    attention_mask = attention_mask.to(dtype=torch.long).reshape(1, -1)\n",
        "    states = torch.cat([torch.zeros((1, padding, model.config.state_dim)), states], dim=1).float()\n",
        "    actions = torch.cat([torch.zeros((1, padding, model.config.act_dim)), actions], dim=1).float()\n",
        "    returns_to_go = torch.cat([torch.zeros((1, padding, 1)), returns_to_go], dim=1).float()\n",
        "    timesteps = torch.cat([torch.zeros((1, padding), dtype=torch.long), timesteps], dim=1)\n",
        "\n",
        "    state_preds, action_preds, return_preds = model.original_forward(\n",
        "        states=states,\n",
        "        actions=actions,\n",
        "        rewards=rewards,\n",
        "        returns_to_go=returns_to_go,\n",
        "        timesteps=timesteps,\n",
        "        attention_mask=attention_mask,\n",
        "        return_dict=False,\n",
        "    )\n",
        "\n",
        "    return action_preds[0, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFPuiNy-qWnP"
      },
      "outputs": [],
      "source": [
        "# build the environment\n",
        "directory = './video'\n",
        "model = model.to(\"cpu\")\n",
        "env = gym.make(\"HalfCheetah-v3\")\n",
        "env = Recorder(env, directory, fps=30)\n",
        "max_ep_len = 1000\n",
        "device = \"cpu\"\n",
        "scale = 1000.0  # normalization for rewards/returns\n",
        "TARGET_RETURN = 12000 / scale  # evaluation is conditioned on a return of 12000, scaled accordingly\n",
        "\n",
        "state_mean = collator.state_mean.astype(np.float32)\n",
        "state_std = collator.state_std.astype(np.float32)\n",
        "print(state_mean)\n",
        "\n",
        "state_dim = env.observation_space.shape[0]\n",
        "act_dim = env.action_space.shape[0]\n",
        "# Create the decision transformer model\n",
        "\n",
        "state_mean = torch.from_numpy(state_mean).to(device=device)\n",
        "state_std = torch.from_numpy(state_std).to(device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysPH9rtRqY-g"
      },
      "outputs": [],
      "source": [
        "# Interact with the environment and create a video\n",
        "episode_return, episode_length = 0, 0\n",
        "state = env.reset()\n",
        "target_return = torch.tensor(TARGET_RETURN, device=device, dtype=torch.float32).reshape(1, 1)\n",
        "states = torch.from_numpy(state).reshape(1, state_dim).to(device=device, dtype=torch.float32)\n",
        "actions = torch.zeros((0, act_dim), device=device, dtype=torch.float32)\n",
        "rewards = torch.zeros(0, device=device, dtype=torch.float32)\n",
        "\n",
        "timesteps = torch.tensor(0, device=device, dtype=torch.long).reshape(1, 1)\n",
        "for t in range(max_ep_len):\n",
        "    actions = torch.cat([actions, torch.zeros((1, act_dim), device=device)], dim=0)\n",
        "    rewards = torch.cat([rewards, torch.zeros(1, device=device)])\n",
        "\n",
        "    action = get_action(\n",
        "        model,\n",
        "        (states - state_mean) / state_std,\n",
        "        actions,\n",
        "        rewards,\n",
        "        target_return,\n",
        "        timesteps,\n",
        "    )\n",
        "    actions[-1] = action\n",
        "    action = action.detach().cpu().numpy()\n",
        "\n",
        "    state, reward, done, _ = env.step(action)\n",
        "\n",
        "    cur_state = torch.from_numpy(state).to(device=device).reshape(1, state_dim)\n",
        "    states = torch.cat([states, cur_state], dim=0)\n",
        "    rewards[-1] = reward\n",
        "\n",
        "    pred_return = target_return[0, -1] - (reward / scale)\n",
        "    target_return = torch.cat([target_return, pred_return.reshape(1, 1)], dim=1)\n",
        "    timesteps = torch.cat([timesteps, torch.ones((1, 1), device=device, dtype=torch.long) * (t + 1)], dim=1)\n",
        "\n",
        "    episode_return += reward\n",
        "    episode_length += 1\n",
        "\n",
        "    if done:\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dn1Zy7x9qbnI"
      },
      "outputs": [],
      "source": [
        "# Play the video\n",
        "env.play()\n",
        "# If you want to convert the video:\n",
        "# !ffmpeg -i {your_video} -vcodec h264 replay.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0MTM3o5xJf8"
      },
      "source": [
        "### Step 8: Publish our trained model on the Hub ðŸ”¥\n",
        "Now that we saw we got good results after the training, we can publish our trained model on the hub ðŸ¤— with one line of code.\n",
        "\n",
        "Under the hood, the Hub uses git-based repositories (don't worry if you don't know what git is), which means you can update the model with new versions as you experiment and improve your agent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLFQfIXLxPpq"
      },
      "source": [
        "To be able to share your model with the community there are three more steps to follow:\n",
        "\n",
        "1ï¸âƒ£ (If it's not already done) create an account to HF âž¡ https://huggingface.co/join\n",
        "\n",
        "2ï¸âƒ£ Sign in and then, you need to store your authentication token from the Hugging Face website.\n",
        "- Create a new token (https://huggingface.co/settings/tokens) **with write role**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IJbhQvrxRVD"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkuqy2bdxUdj"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIBqBv95xS7M"
      },
      "source": [
        "If you don't want to use a Google Colab or a Jupyter Notebook, you need to use this command instead: `huggingface-cli login`\n",
        "\n",
        "3ï¸âƒ£ We're now ready to push our trained model to the ðŸ¤— Hub ðŸ”¥ !!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZwU9gfMxbht"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EgwxEjOxkBS"
      },
      "source": [
        "## Some additional challenges ðŸ†\n",
        "Congratulations, you've just trained your first Decision Transformer ðŸ¥³.\n",
        "\n",
        "Now, the best way to learn **is to try things by your own**! Why not trying with another environment?\n",
        "\n",
        "We provide datasets for some other environments:\n",
        "* [Walker2D](https://huggingface.co/edbeeching/decision-transformer-gym-walker2d-expert)\n",
        "* [Hopper](https://huggingface.co/edbeeching/decision-transformer-gym-hopper-expert)\n",
        "\n",
        "\n",
        "Have fun!\n",
        "\n",
        "### Keep Learning, Stay awesome ðŸ¤—\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "doan",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c909ce3f6754c39b2add96ae96a13e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_170986fda1f844df8e92231240409065",
            "max": 60,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d6d9e83033a458d87acb109adf9dd88",
            "value": 60
          }
        },
        "170986fda1f844df8e92231240409065": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a27b31cc5a7434ea72664cb27cc2d38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33956b8453ce414a98fe2d9e8c9c62ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39dc519caba34bbdb40cce231326d52e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f6b8104267844168a3d1db57e9ff1cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f75f9ba8a76494191c15650dfe6795b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52f428497cab4f1788280acde19decf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56835655eddf40a1ab5388ee38147c9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8860038891054cffa38652154ba8d856",
              "IPY_MODEL_0c909ce3f6754c39b2add96ae96a13e1",
              "IPY_MODEL_988ef73b582b446c88b6e617f3f3b4cf"
            ],
            "layout": "IPY_MODEL_9f9a04e8b76040fcb4dd077b91d0b178"
          }
        },
        "6126b69f6487464b88f14fef402d7205": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f6b8104267844168a3d1db57e9ff1cc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3f75f9ba8a76494191c15650dfe6795b",
            "value": "â€‡20/20â€‡[00:14&lt;00:00,â€‡â€‡1.39â€‡examples/s]"
          }
        },
        "6d6d9e83033a458d87acb109adf9dd88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "742a243e329a4bf298f16cffa75c45cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82d4764120c84a3f8d4e922bee341d26": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8860038891054cffa38652154ba8d856": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a27b31cc5a7434ea72664cb27cc2d38",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b09f2d00fef64fa192c3b9cff67f6d15",
            "value": "Savingâ€‡theâ€‡datasetâ€‡(3/3â€‡shards):â€‡100%"
          }
        },
        "988ef73b582b446c88b6e617f3f3b4cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82d4764120c84a3f8d4e922bee341d26",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_742a243e329a4bf298f16cffa75c45cd",
            "value": "â€‡60/60â€‡[00:15&lt;00:00,â€‡â€‡4.29â€‡examples/s]"
          }
        },
        "9cb62e32616c4217bff31960b48aac7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f66b5dc66bec473c9687959a86dede69",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_33956b8453ce414a98fe2d9e8c9c62ed",
            "value": "Savingâ€‡theâ€‡datasetâ€‡(1/1â€‡shards):â€‡100%"
          }
        },
        "9f9a04e8b76040fcb4dd077b91d0b178": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8a8acb31c1743d1b09233d06f5329e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9cb62e32616c4217bff31960b48aac7a",
              "IPY_MODEL_fa7c562dd6ac489285bfcb53a738e216",
              "IPY_MODEL_6126b69f6487464b88f14fef402d7205"
            ],
            "layout": "IPY_MODEL_52f428497cab4f1788280acde19decf8"
          }
        },
        "b09f2d00fef64fa192c3b9cff67f6d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf578bd1a7cc4f0a94564a2a564ba991": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f66b5dc66bec473c9687959a86dede69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa7c562dd6ac489285bfcb53a738e216": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39dc519caba34bbdb40cce231326d52e",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf578bd1a7cc4f0a94564a2a564ba991",
            "value": 20
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
